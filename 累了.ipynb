{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richie0115/PD/blob/main/%E7%B4%AF%E4%BA%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta\n",
        "!pip install arch\n",
        "!pip install pmdarima\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install statsmodels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOkrCbCTb8i5",
        "outputId": "c44575ba-1f46-4e8c-cc53-4d496739b788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
            "Requirement already satisfied: arch in /usr/local/lib/python3.10/dist-packages (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from arch) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from arch) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from arch) (2.1.4)\n",
            "Requirement already satisfied: statsmodels>=0.12 in /usr/local/lib/python3.10/dist-packages (from arch) (0.14.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->arch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->arch) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->arch) (2024.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.12->arch) (1.16.0)\n",
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.10/dist-packages (2.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.4.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (3.0.11)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (0.14.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (2.0.7)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (71.0.4)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.2)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.26.4)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.1.4)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from arch import arch_model\n",
        "\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Is_KYFRJb-MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, BatchNormalization, Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import xgboost as xgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from arch import arch_model\n"
      ],
      "metadata": {
        "id": "KhDM4DOxb_yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# LSTM\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(seq_length, len(data)):\n",
        "        X.append(data[i-seq_length:i, :-1])\n",
        "        y.append(data[i, -1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def train_lstm(X, y, sequence_length=60):\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X = X.values\n",
        "    if isinstance(y, pd.Series):\n",
        "        y = y.values\n",
        "\n",
        "    data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
        "\n",
        "    # 創建序列數據\n",
        "    X_seq, y_seq = create_sequences(data, sequence_length)\n",
        "    # 分割訓練集和測試集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
        "\n",
        "    # 建立LSTM模型\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    # 定義早停和學習率衰減回調\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "\n",
        "    # 訓練模型\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "    return model, sequence_length, X_test, y_test\n",
        "\n",
        "# CNN+LSTM\n",
        "def train_cnn_lstm(X, y):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(np.concatenate((X, y.values.reshape(-1, 1)), axis=1))\n",
        "\n",
        "    def create_sequences(data, seq_length):\n",
        "        X, y = [], []\n",
        "        for i in range(seq_length, len(data)):\n",
        "            X.append(data[i-seq_length:i, :-1])\n",
        "            y.append(data[i, -1])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    sequence_length = 60\n",
        "    X_seq, y_seq = create_sequences(scaled_data, sequence_length)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping, reduce_lr])\n",
        "    return model, scaler, sequence_length, X_test, y_test\n",
        "\n",
        "# 隨機森林\n",
        "def train_random_forest(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('rf', RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=5, min_samples_leaf=4, bootstrap=True))\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    return pipeline, X_test, y_test\n",
        "\n",
        "# SVR\n",
        "def train_svr(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    svr = SVR(kernel='linear', C=0.1, gamma='scale', epsilon=0.01)\n",
        "    svr.fit(X_train_scaled, y_train)\n",
        "    return svr, scaler, X_test_scaled, y_test\n",
        "\n",
        "# XGBoost\n",
        "def train_xgboost(X, y):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "    xgb_model = xgb.XGBRegressor(\n",
        "        objective='reg:squarederror', booster='gbtree', eval_metric='rmse',\n",
        "        n_estimators=500, learning_rate=0.1, max_depth=5, min_child_weight=10,\n",
        "        subsample=0.9, colsample_bytree=0.8, gamma=0, alpha=0.01, reg_lambda=1, random_state=42\n",
        "    )\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    return xgb_model, X_test, y_test\n",
        "\n",
        "# Transformer\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "def train_transformer(X, y):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = TransformerModel(input_dim=input_dim).to(device)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    num_epochs = 50\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "    return model, scaler, X_test_tensor, y_test_tensor\n",
        "\n",
        "# ARIMA+GARCH\n",
        "def train_arima_garch(df, target):\n",
        "    arima_order = (5, 1, 0)\n",
        "    model_arima = ARIMA(df[target], order=arima_order)\n",
        "    model_fit_arima = model_arima.fit()\n",
        "\n",
        "    resid = model_fit_arima.resid\n",
        "    model_garch = arch_model(resid, vol='Garch', p=1, q=1)\n",
        "    model_fit_garch = model_garch.fit(disp='off')\n",
        "\n",
        "    forecast_arima = model_fit_arima.forecast(steps=1)\n",
        "    forecast_garch = model_fit_garch.forecast(horizon=1)\n",
        "    next_return = forecast_arima.values[-1] + forecast_garch.variance.values[-1]\n",
        "\n",
        "    return next_return\n",
        "\n",
        "# 每個模型的呼叫\n",
        "lstm_model, lstm_seq_len, X_test_lstm, y_test_lstm = train_lstm(df[features], df[target])\n",
        "cnn_lstm_model, cnn_lstm_scaler, cnn_lstm_seq_len, X_test_cnn_lstm, y_test_cnn_lstm = train_cnn_lstm(df[features], df[target])\n",
        "rf_model, X_test_rf, y_test_rf = train_random_forest(df[features], df[target])\n",
        "svr_model, svr_scaler, X_test_svr, y_test_svr = train_svr(df[features], df[target])\n",
        "xgb_model, X_test_xgb, y_test_xgb = train_xgboost(df[features], df[target])\n",
        "transformer_model, transformer_scaler, X_test_transformer, y_test_transformer = train_transformer(df[features], df[target])\n",
        "next_return_arima_garch = train_arima_garch(df, target)\n",
        "\n",
        "# 預測\n",
        "# LSTM\n",
        "lstm_pred = lstm_model.predict(X_test_lstm[-1].reshape(1, lstm_seq_len, X_test_lstm.shape[2]))[0][0]\n",
        "\n",
        "# CNN+LSTM\n",
        "cnn_lstm_pred = cnn_lstm_model.predict(X_test_cnn_lstm[-1].reshape(1, cnn_lstm_seq_len, X_test_cnn_lstm.shape[2]))[0][0]\n",
        "\n",
        "# RF\n",
        "rf_pred = rf_model.predict(X_test_rf.iloc[-1].values.reshape(1, -1))[0]\n",
        "\n",
        "# SVR\n",
        "svr_pred = svr_model.predict(X_test_svr[-1].reshape(1, -1))[0]\n",
        "# svr_pred = svr_model.predict(X_test_svr.iloc[-1].reshape(1, -1))[0]\n",
        "\n",
        "# XGBoost\n",
        "xgb_pred = xgb_model.predict(X_test_xgb[-1].reshape(1, -1))[0]\n",
        "# xgb_pred = xgb_model.predict(X_test_xgb.iloc[-1].reshape(1, -1))[0]\n",
        "\n",
        "# Transformer\n",
        "transformer_pred = transformer_model(X_test_transformer[-1].view(1, -1)).cpu().detach().numpy()[0][0]\n",
        "\n",
        "\n",
        "# 主迴圈\n",
        "iterations = 100  # 定義迴圈次數\n",
        "results = []\n",
        "\n",
        "for i in range(iterations):\n",
        "    print(f'第 {i+1} 次實驗：')\n",
        "\n",
        "    # 讀取原始Excel文件並複製\n",
        "    df_original = pd.read_excel('AMD.xlsx')\n",
        "    df = df_original.copy()\n",
        "\n",
        "    # 隨機刪除數據\n",
        "    if len(df) > 2500:\n",
        "        delete_point = random.randint(2501, len(df))\n",
        "        df = df.iloc[:delete_point]\n",
        "\n",
        "    df.ffill(inplace=True)\n",
        "    df.bfill(inplace=True)\n",
        "\n",
        "    # 重新計算日期轉換和 last_date_numeric\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df['Date_numeric'] = df['Date'].dt.strftime('%Y%m%d').astype(int)\n",
        "    last_date_numeric = df['Date_numeric'].iloc[-1]\n",
        "\n",
        "    # 定義特徵和目標變數\n",
        "    features = [\"Date_numeric\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"MA14\",\n",
        "                \"RSI14\", \"RSI28\", \"RSI50\", \"EMA30\", \"EMA60\", \"EMA90\",\n",
        "                \"AROON_UP25\", \"AROON_DOWN25\", \"AROON_UP50\", \"AROON_DOWN50\",\n",
        "                \"current_ratio\", \"quick_ratio\", \"debt_ratio\", \"gross_margin\",\n",
        "                \"operating_margin\", \"roe\", \"net_profit_margin\",\n",
        "                \"diluted_earing_per_share\", \"operating_cash_flow_margin\",\n",
        "                \"cash_flow_coverage_ratio\", \"DAILYRETURN\", \"WMA14\", \"WMA20\", \"WMA200\", \"std20\", \"UPPER_BAND\", \"LOWER_BAND\", \"MACD\", \"RVI\"]\n",
        "\n",
        "    target = 'DAILYRETURN'\n",
        "    X = df[features]\n",
        "    y = df[target]\n",
        "\n",
        "    # 訓練和預測\n",
        "    lstm_model, lstm_seq_len, X_test_lstm, y_test_lstm = train_lstm(X, y)\n",
        "    cnn_lstm_model, cnn_lstm_scaler, cnn_lstm_seq_len, X_test_cnn_lstm, y_test_cnn_lstm = train_cnn_lstm(X, y)\n",
        "    rf_model, X_test_rf, y_test_rf = train_random_forest(X, y)\n",
        "    svr_model, svr_scaler, X_test_svr, y_test_svr = train_svr(X, y)\n",
        "    xgb_model, X_test_xgb, y_test_xgb = train_xgboost(X, y)\n",
        "    transformer_model, transformer_scaler, X_test_transformer, y_test_transformer = train_transformer(X, y)\n",
        "    next_return_arima_garch = train_arima_garch(df, target)\n",
        "\n",
        "    # 預測\n",
        "    lstm_pred = lstm_model.predict(X_test_lstm[-1].reshape(1, lstm_seq_len, X_test_lstm.shape[2]))[0][0]\n",
        "    cnn_lstm_pred = cnn_lstm_model.predict(X_test_cnn_lstm[-1].reshape(1, cnn_lstm_seq_len, X_test_cnn_lstm.shape[2]))[0][0]\n",
        "    rf_pred = rf_model.predict(X_test_rf.iloc[-1].values.reshape(1, -1))[0]\n",
        "    svr_pred = svr_model.predict(X_test_svr[-1].reshape(1, -1))[0]\n",
        "    xgb_pred = xgb_model.predict(X_test_xgb[-1].reshape(1, -1))[0]\n",
        "    transformer_pred = transformer_model(X_test_transformer[-1].view(1, -1)).cpu().detach().numpy()[0][0]\n",
        "\n",
        "    # 紀錄結果，包括最後一項的 Date_numeric\n",
        "    result = f'第 {i+1} 次實驗結果 (最後一項 Date_numeric: {last_date_numeric}):\\n'\n",
        "    result += f'LSTM模型預測結果: {lstm_pred*100}%\\n'\n",
        "    result += f'CNN+LSTM模型預測結果: {cnn_lstm_pred*10}%\\n'\n",
        "    result += f'隨機森林模型預測結果: {rf_pred*100}%\\n'\n",
        "    result += f'SVR模型預測結果: {svr_pred*100}%\\n'\n",
        "    result += f'XGBoost模型預測結果: {xgb_pred*100}%\\n'\n",
        "    result += f'Transformer模型預測結果: {transformer_pred*100}%\\n'\n",
        "    result += f'ARIMA+GARCH模型預測結果: {next_return_arima_garch*100}%\\n'\n",
        "\n",
        "    results.append(result)\n",
        "    print(result)\n",
        "\n",
        "# 將所有結果寫入txt檔案\n",
        "with open('experiment_results.txt', 'w') as f:\n",
        "    for result in results:\n",
        "        f.write(result + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t27NdSQvcB4I",
        "outputId": "be0438dc-1d3c-47a8-94eb-a049bf7c6a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 437ms/step - loss: 0.0864 - mae: 0.2327 - val_loss: 0.0112 - val_mae: 0.0928 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 333ms/step - loss: 0.0287 - mae: 0.1325 - val_loss: 0.0046 - val_mae: 0.0567 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 212ms/step - loss: 0.0121 - mae: 0.0838 - val_loss: 0.0014 - val_mae: 0.0304 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0057 - mae: 0.0561 - val_loss: 0.0014 - val_mae: 0.0305 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.0033 - mae: 0.0445 - val_loss: 9.4558e-04 - val_mae: 0.0232 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 233ms/step - loss: 0.0024 - mae: 0.0364 - val_loss: 8.9371e-04 - val_mae: 0.0225 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 222ms/step - loss: 0.0021 - mae: 0.0331 - val_loss: 8.9420e-04 - val_mae: 0.0227 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 243ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 8.8782e-04 - val_mae: 0.0225 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 253ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 9.2196e-04 - val_mae: 0.0225 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 221ms/step - loss: 0.0022 - mae: 0.0295 - val_loss: 9.1312e-04 - val_mae: 0.0233 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 219ms/step - loss: 0.0018 - mae: 0.0278 - val_loss: 9.0643e-04 - val_mae: 0.0231 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 8.8414e-04 - val_mae: 0.0222 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 8.8380e-04 - val_mae: 0.0224 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 8.8739e-04 - val_mae: 0.0225 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.8795e-04 - val_mae: 0.0226 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 8.8669e-04 - val_mae: 0.0225 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 8.8699e-04 - val_mae: 0.0225 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 229ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.8679e-04 - val_mae: 0.0225 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 0.0018 - mae: 0.0285 - val_loss: 8.8571e-04 - val_mae: 0.0225 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 219ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 8.8439e-04 - val_mae: 0.0224 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 8.8513e-04 - val_mae: 0.0224 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 8.8483e-04 - val_mae: 0.0224 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 212ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.8465e-04 - val_mae: 0.0224 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 158ms/step - loss: 0.1659 - mae: 0.3156 - val_loss: 0.0430 - val_mae: 0.2026 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - loss: 0.0230 - mae: 0.1190 - val_loss: 0.0018 - val_mae: 0.0318 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - loss: 0.0066 - mae: 0.0641 - val_loss: 0.0094 - val_mae: 0.0896 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - loss: 0.0049 - mae: 0.0545 - val_loss: 0.0089 - val_mae: 0.0871 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0051 - mae: 0.0543 - val_loss: 0.0027 - val_mae: 0.0441 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - loss: 0.0039 - mae: 0.0470 - val_loss: 0.0016 - val_mae: 0.0314 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 131ms/step - loss: 0.0045 - mae: 0.0465 - val_loss: 0.0016 - val_mae: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - loss: 0.0038 - mae: 0.0463 - val_loss: 0.0016 - val_mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 107ms/step - loss: 0.0042 - mae: 0.0468 - val_loss: 0.0018 - val_mae: 0.0319 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0041 - mae: 0.0457 - val_loss: 0.0027 - val_mae: 0.0422 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0034 - mae: 0.0425 - val_loss: 0.0030 - val_mae: 0.0450 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 143ms/step - loss: 0.0030 - mae: 0.0412 - val_loss: 0.0021 - val_mae: 0.0353 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 145ms/step - loss: 0.0033 - mae: 0.0419 - val_loss: 0.0018 - val_mae: 0.0318 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - loss: 0.0033 - mae: 0.0427 - val_loss: 0.0021 - val_mae: 0.0361 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0034 - mae: 0.0427 - val_loss: 0.0019 - val_mae: 0.0336 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0021 - val_mae: 0.0351 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0022 - val_mae: 0.0365 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001574. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
            "第 1 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 224ms/step - loss: 0.1421 - mae: 0.2856 - val_loss: 0.0315 - val_mae: 0.1578 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step - loss: 0.0377 - mae: 0.1539 - val_loss: 0.0076 - val_mae: 0.0746 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 0.0192 - mae: 0.1064 - val_loss: 0.0049 - val_mae: 0.0596 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 0.0086 - mae: 0.0704 - val_loss: 0.0017 - val_mae: 0.0321 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0016 - val_mae: 0.0309 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 0.0036 - mae: 0.0419 - val_loss: 0.0015 - val_mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 194ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0015 - val_mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 246ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0015 - val_mae: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0018 - mae: 0.0303 - val_loss: 0.0014 - val_mae: 0.0294 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0015 - val_mae: 0.0304 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 186ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0294 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 0.0017 - mae: 0.0265 - val_loss: 0.0014 - val_mae: 0.0299 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0300 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 215ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 212ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 166ms/step - loss: 0.1878 - mae: 0.3397 - val_loss: 0.0114 - val_mae: 0.0923 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - loss: 0.0405 - mae: 0.1544 - val_loss: 0.0168 - val_mae: 0.1192 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0075 - mae: 0.0690 - val_loss: 0.0262 - val_mae: 0.1541 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0051 - mae: 0.0555 - val_loss: 0.0165 - val_mae: 0.1188 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - loss: 0.0046 - mae: 0.0519 - val_loss: 0.0033 - val_mae: 0.0466 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - loss: 0.0038 - mae: 0.0456 - val_loss: 0.0030 - val_mae: 0.0442 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0037 - mae: 0.0461 - val_loss: 0.0026 - val_mae: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - loss: 0.0037 - mae: 0.0448 - val_loss: 0.0026 - val_mae: 0.0400 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 0.0034 - mae: 0.0445 - val_loss: 0.0029 - val_mae: 0.0428 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - loss: 0.0036 - mae: 0.0448 - val_loss: 0.0033 - val_mae: 0.0460 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0032 - mae: 0.0431 - val_loss: 0.0032 - val_mae: 0.0455 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - loss: 0.0033 - mae: 0.0423 - val_loss: 0.0029 - val_mae: 0.0428 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - loss: 0.0029 - mae: 0.0399 - val_loss: 0.0026 - val_mae: 0.0406 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - loss: 0.0033 - mae: 0.0419 - val_loss: 0.0028 - val_mae: 0.0419 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0031 - mae: 0.0413 - val_loss: 0.0029 - val_mae: 0.0433 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - loss: 0.0032 - mae: 0.0405 - val_loss: 0.0029 - val_mae: 0.0433 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.0039 - mae: 0.0412 - val_loss: 0.0027 - val_mae: 0.0410 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001553. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step\n",
            "第 1 次實驗結果 (最後一項 Date_numeric: 20240806):\n",
            "LSTM模型預測結果: 0.003541354089975357%\n",
            "CNN+LSTM模型預測結果: 3.351547122001648%\n",
            "隨機森林模型預測結果: 3.2872315945965456%\n",
            "SVR模型預測結果: -4.3516966171884315%\n",
            "XGBoost模型預測結果: -2.1461309865117073%\n",
            "Transformer模型預測結果: -4.632044583559036%\n",
            "ARIMA+GARCH模型預測結果: [-0.82058789]%\n",
            "\n",
            "第 2 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 202ms/step - loss: 0.1159 - mae: 0.2576 - val_loss: 0.0031 - val_mae: 0.0447 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 198ms/step - loss: 0.0320 - mae: 0.1383 - val_loss: 0.0022 - val_mae: 0.0370 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 215ms/step - loss: 0.0131 - mae: 0.0892 - val_loss: 0.0014 - val_mae: 0.0299 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0065 - mae: 0.0618 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 0.0016 - val_mae: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 0.0024 - mae: 0.0366 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0015 - val_mae: 0.0305 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0015 - val_mae: 0.0312 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0014 - val_mae: 0.0301 - learning_rate: 2.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 215ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 4.0000e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0294 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 8.0000e-06\n",
            "Epoch 20/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 208ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 1.6000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 1.6000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 1.6000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - loss: 0.1566 - mae: 0.3150 - val_loss: 0.0185 - val_mae: 0.1265 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - loss: 0.0401 - mae: 0.1558 - val_loss: 0.0031 - val_mae: 0.0431 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0082 - mae: 0.0706 - val_loss: 0.0194 - val_mae: 0.1301 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - loss: 0.0052 - mae: 0.0545 - val_loss: 0.0133 - val_mae: 0.1047 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 143ms/step - loss: 0.0048 - mae: 0.0520 - val_loss: 0.0061 - val_mae: 0.0659 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - loss: 0.0041 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0504 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 141ms/step - loss: 0.0039 - mae: 0.0465 - val_loss: 0.0024 - val_mae: 0.0385 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0041 - mae: 0.0464 - val_loss: 0.0025 - val_mae: 0.0388 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - loss: 0.0038 - mae: 0.0445 - val_loss: 0.0035 - val_mae: 0.0479 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 134ms/step - loss: 0.0037 - mae: 0.0443 - val_loss: 0.0025 - val_mae: 0.0389 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 0.0039 - mae: 0.0456 - val_loss: 0.0029 - val_mae: 0.0427 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - loss: 0.0033 - mae: 0.0437 - val_loss: 0.0030 - val_mae: 0.0437 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 130ms/step - loss: 0.0031 - mae: 0.0420 - val_loss: 0.0026 - val_mae: 0.0398 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 0.0030 - mae: 0.0409 - val_loss: 0.0025 - val_mae: 0.0392 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 144ms/step - loss: 0.0029 - mae: 0.0392 - val_loss: 0.0026 - val_mae: 0.0402 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - loss: 0.0033 - mae: 0.0426 - val_loss: 0.0026 - val_mae: 0.0401 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 0.0033 - mae: 0.0405 - val_loss: 0.0026 - val_mae: 0.0402 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001553. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f09652569e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f0964fddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 2 次實驗結果 (最後一項 Date_numeric: 20240725):\n",
            "LSTM模型預測結果: 0.572223961353302%\n",
            "CNN+LSTM模型預測結果: 2.699417471885681%\n",
            "隨機森林模型預測結果: -4.286651971655546%\n",
            "SVR模型預測結果: -5.338822360316401%\n",
            "XGBoost模型預測結果: -4.582753032445908%\n",
            "Transformer模型預測結果: -4.929041862487793%\n",
            "ARIMA+GARCH模型預測結果: [-2.31200478]%\n",
            "\n",
            "第 3 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.1196 - mae: 0.2749 - val_loss: 0.0110 - val_mae: 0.0939 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - loss: 0.0380 - mae: 0.1524 - val_loss: 0.0088 - val_mae: 0.0821 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0159 - mae: 0.0978 - val_loss: 0.0018 - val_mae: 0.0335 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - loss: 0.0068 - mae: 0.0640 - val_loss: 0.0015 - val_mae: 0.0297 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - loss: 0.0041 - mae: 0.0473 - val_loss: 0.0014 - val_mae: 0.0292 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0014 - val_mae: 0.0289 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.0014 - val_mae: 0.0286 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0013 - val_mae: 0.0286 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0017 - mae: 0.0300 - val_loss: 0.0014 - val_mae: 0.0291 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0014 - val_mae: 0.0294 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 261ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 0.0014 - val_mae: 0.0289 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0014 - val_mae: 0.0291 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0014 - val_mae: 0.0291 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0014 - val_mae: 0.0289 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 215ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 134ms/step - loss: 0.2254 - mae: 0.3706 - val_loss: 0.0032 - val_mae: 0.0449 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 0.0391 - mae: 0.1547 - val_loss: 0.0047 - val_mae: 0.0551 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - loss: 0.0073 - mae: 0.0646 - val_loss: 0.0181 - val_mae: 0.1233 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0054 - mae: 0.0579 - val_loss: 0.0140 - val_mae: 0.1071 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - loss: 0.0044 - mae: 0.0507 - val_loss: 0.0064 - val_mae: 0.0680 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 0.0041 - mae: 0.0475 - val_loss: 0.0049 - val_mae: 0.0574 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - loss: 0.0043 - mae: 0.0486 - val_loss: 0.0027 - val_mae: 0.0402 - learning_rate: 2.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0040 - mae: 0.0465 - val_loss: 0.0027 - val_mae: 0.0399 - learning_rate: 2.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - loss: 0.0040 - mae: 0.0477 - val_loss: 0.0025 - val_mae: 0.0388 - learning_rate: 2.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 0.0041 - mae: 0.0481 - val_loss: 0.0026 - val_mae: 0.0392 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.0025 - val_mae: 0.0391 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 141ms/step - loss: 0.0041 - mae: 0.0470 - val_loss: 0.0025 - val_mae: 0.0388 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - loss: 0.0035 - mae: 0.0441 - val_loss: 0.0025 - val_mae: 0.0385 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0035 - mae: 0.0443 - val_loss: 0.0025 - val_mae: 0.0385 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - loss: 0.0036 - mae: 0.0444 - val_loss: 0.0025 - val_mae: 0.0385 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - loss: 0.0034 - mae: 0.0433 - val_loss: 0.0025 - val_mae: 0.0385 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0036 - mae: 0.0438 - val_loss: 0.0025 - val_mae: 0.0385 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0036 - mae: 0.0450 - val_loss: 0.0025 - val_mae: 0.0384 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - loss: 0.0036 - mae: 0.0450 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - loss: 0.0035 - mae: 0.0445 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 107ms/step - loss: 0.0032 - mae: 0.0431 - val_loss: 0.0025 - val_mae: 0.0385 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0037 - mae: 0.0453 - val_loss: 0.0025 - val_mae: 0.0384 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 0.0038 - mae: 0.0452 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - loss: 0.0034 - mae: 0.0438 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0024 - val_mae: 0.0383 - learning_rate: 1.6000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0037 - mae: 0.0450 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 1.6000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - loss: 0.0037 - mae: 0.0448 - val_loss: 0.0024 - val_mae: 0.0383 - learning_rate: 1.6000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.0041 - mae: 0.0449 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 1.6000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 142ms/step - loss: 0.0035 - mae: 0.0443 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 1.6000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001552. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 3 次實驗結果 (最後一項 Date_numeric: 20240710):\n",
            "LSTM模型預測結果: 0.3881540149450302%\n",
            "CNN+LSTM模型預測結果: 2.8640976548194885%\n",
            "隨機森林模型預測結果: 2.364616226702887%\n",
            "SVR模型預測結果: 3.241050975787776%\n",
            "XGBoost模型預測結果: 2.3760955780744553%\n",
            "Transformer模型預測結果: 4.4548992067575455%\n",
            "ARIMA+GARCH模型預測結果: [2.48551093]%\n",
            "\n",
            "第 4 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 223ms/step - loss: 0.1104 - mae: 0.2595 - val_loss: 0.0055 - val_mae: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0312 - mae: 0.1398 - val_loss: 0.0061 - val_mae: 0.0699 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 0.0156 - mae: 0.0982 - val_loss: 8.8924e-04 - val_mae: 0.0228 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0069 - mae: 0.0629 - val_loss: 7.7374e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 7.7901e-04 - val_mae: 0.0216 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0028 - mae: 0.0408 - val_loss: 7.3977e-04 - val_mae: 0.0204 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0025 - mae: 0.0350 - val_loss: 7.4190e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 7.4736e-04 - val_mae: 0.0211 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 7.3865e-04 - val_mae: 0.0208 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0020 - mae: 0.0293 - val_loss: 7.3742e-04 - val_mae: 0.0208 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 7.3737e-04 - val_mae: 0.0208 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 7.3461e-04 - val_mae: 0.0205 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 7.3715e-04 - val_mae: 0.0207 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 256ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 7.3729e-04 - val_mae: 0.0208 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 220ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 7.3571e-04 - val_mae: 0.0207 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 7.3739e-04 - val_mae: 0.0208 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 204ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 7.3831e-04 - val_mae: 0.0208 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 7.3843e-04 - val_mae: 0.0208 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 7.3829e-04 - val_mae: 0.0208 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 192ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 7.3787e-04 - val_mae: 0.0208 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 7.3876e-04 - val_mae: 0.0208 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.3860e-04 - val_mae: 0.0208 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - loss: 0.1892 - mae: 0.3423 - val_loss: 0.0290 - val_mae: 0.1661 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - loss: 0.0378 - mae: 0.1513 - val_loss: 0.0040 - val_mae: 0.0563 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0078 - mae: 0.0686 - val_loss: 0.0175 - val_mae: 0.1275 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - loss: 0.0054 - mae: 0.0561 - val_loss: 0.0098 - val_mae: 0.0926 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - loss: 0.0055 - mae: 0.0557 - val_loss: 0.0066 - val_mae: 0.0742 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - loss: 0.0043 - mae: 0.0494 - val_loss: 0.0023 - val_mae: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0038 - mae: 0.0471 - val_loss: 0.0013 - val_mae: 0.0275 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0040 - mae: 0.0461 - val_loss: 0.0017 - val_mae: 0.0310 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 142ms/step - loss: 0.0042 - mae: 0.0474 - val_loss: 0.0019 - val_mae: 0.0336 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0035 - mae: 0.0439 - val_loss: 0.0013 - val_mae: 0.0275 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0037 - mae: 0.0449 - val_loss: 0.0018 - val_mae: 0.0334 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 0.0031 - mae: 0.0416 - val_loss: 0.0018 - val_mae: 0.0327 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0015 - val_mae: 0.0292 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 0.0018 - val_mae: 0.0325 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - loss: 0.0034 - mae: 0.0432 - val_loss: 0.0015 - val_mae: 0.0292 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0030 - mae: 0.0404 - val_loss: 0.0016 - val_mae: 0.0303 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 143ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0017 - val_mae: 0.0321 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001577. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
            "第 4 次實驗結果 (最後一項 Date_numeric: 20240110):\n",
            "LSTM模型預測結果: -0.12501151068136096%\n",
            "CNN+LSTM模型預測結果: 3.109583854675293%\n",
            "隨機森林模型預測結果: -9.867987975412384e-07%\n",
            "SVR模型預測結果: -1.0208290918290672%\n",
            "XGBoost模型預測結果: -2.9593121260404587%\n",
            "Transformer模型預測結果: 0.4553787410259247%\n",
            "ARIMA+GARCH模型預測結果: [1.35250757]%\n",
            "\n",
            "第 5 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 230ms/step - loss: 0.0786 - mae: 0.2151 - val_loss: 0.0277 - val_mae: 0.1522 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 225ms/step - loss: 0.0215 - mae: 0.1141 - val_loss: 0.0019 - val_mae: 0.0343 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0097 - mae: 0.0769 - val_loss: 0.0021 - val_mae: 0.0367 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 0.0015 - val_mae: 0.0316 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 226ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0015 - val_mae: 0.0308 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 226ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.0014 - val_mae: 0.0301 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 229ms/step - loss: 0.0027 - mae: 0.0333 - val_loss: 0.0014 - val_mae: 0.0299 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0015 - val_mae: 0.0312 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0018 - mae: 0.0281 - val_loss: 0.0014 - val_mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 228ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0015 - val_mae: 0.0306 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 256ms/step - loss: 0.0018 - mae: 0.0281 - val_loss: 0.0014 - val_mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - loss: 0.0021 - mae: 0.0288 - val_loss: 0.0014 - val_mae: 0.0299 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0014 - val_mae: 0.0301 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0302 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 228ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0014 - val_mae: 0.0301 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 230ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0014 - val_mae: 0.0300 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0301 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.1401 - mae: 0.2957 - val_loss: 0.0276 - val_mae: 0.1535 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0234 - mae: 0.1190 - val_loss: 0.0040 - val_mae: 0.0502 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - loss: 0.0065 - mae: 0.0610 - val_loss: 0.0140 - val_mae: 0.1073 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 0.0048 - mae: 0.0536 - val_loss: 0.0109 - val_mae: 0.0928 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - loss: 0.0047 - mae: 0.0503 - val_loss: 0.0069 - val_mae: 0.0710 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0031 - val_mae: 0.0453 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - loss: 0.0036 - mae: 0.0450 - val_loss: 0.0026 - val_mae: 0.0417 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 107ms/step - loss: 0.0037 - mae: 0.0444 - val_loss: 0.0027 - val_mae: 0.0413 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0032 - mae: 0.0417 - val_loss: 0.0026 - val_mae: 0.0404 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - loss: 0.0036 - mae: 0.0436 - val_loss: 0.0026 - val_mae: 0.0404 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - loss: 0.0032 - mae: 0.0411 - val_loss: 0.0027 - val_mae: 0.0425 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0033 - mae: 0.0416 - val_loss: 0.0030 - val_mae: 0.0433 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0027 - val_mae: 0.0416 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0027 - val_mae: 0.0413 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - loss: 0.0030 - mae: 0.0399 - val_loss: 0.0028 - val_mae: 0.0423 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 0.0030 - mae: 0.0394 - val_loss: 0.0027 - val_mae: 0.0414 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 140ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0027 - val_mae: 0.0412 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - loss: 0.0028 - mae: 0.0387 - val_loss: 0.0027 - val_mae: 0.0412 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0030 - mae: 0.0393 - val_loss: 0.0028 - val_mae: 0.0420 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001551. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n",
            "第 5 次實驗結果 (最後一項 Date_numeric: 20240819):\n",
            "LSTM模型預測結果: 0.4209151491522789%\n",
            "CNN+LSTM模型預測結果: 3.2298746705055237%\n",
            "隨機森林模型預測結果: 2.2528463671899557%\n",
            "SVR模型預測結果: 3.895461657194632%\n",
            "XGBoost模型預測結果: -1.7744682729244232%\n",
            "Transformer模型預測結果: 4.788178950548172%\n",
            "ARIMA+GARCH模型預測結果: [2.34938074]%\n",
            "\n",
            "第 6 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 199ms/step - loss: 0.0721 - mae: 0.2077 - val_loss: 0.0053 - val_mae: 0.0624 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - loss: 0.0237 - mae: 0.1206 - val_loss: 0.0014 - val_mae: 0.0291 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 213ms/step - loss: 0.0111 - mae: 0.0797 - val_loss: 0.0012 - val_mae: 0.0268 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 185ms/step - loss: 0.0050 - mae: 0.0549 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 208ms/step - loss: 0.0032 - mae: 0.0428 - val_loss: 0.0012 - val_mae: 0.0276 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 0.0021 - mae: 0.0343 - val_loss: 0.0011 - val_mae: 0.0256 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0011 - val_mae: 0.0257 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0257 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 214ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0011 - val_mae: 0.0265 - learning_rate: 2.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0260 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 238ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 215ms/step - loss: 0.0021 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 4.0000e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0260 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 217ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0261 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 164ms/step - loss: 0.1872 - mae: 0.3406 - val_loss: 0.0393 - val_mae: 0.1917 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 147ms/step - loss: 0.0473 - mae: 0.1726 - val_loss: 0.0036 - val_mae: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - loss: 0.0092 - mae: 0.0739 - val_loss: 0.0148 - val_mae: 0.1118 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - loss: 0.0053 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.1189 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - loss: 0.0047 - mae: 0.0506 - val_loss: 0.0084 - val_mae: 0.0817 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - loss: 0.0045 - mae: 0.0510 - val_loss: 0.0032 - val_mae: 0.0463 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 0.0040 - mae: 0.0458 - val_loss: 0.0019 - val_mae: 0.0342 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - loss: 0.0041 - mae: 0.0480 - val_loss: 0.0022 - val_mae: 0.0369 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 150ms/step - loss: 0.0035 - mae: 0.0455 - val_loss: 0.0023 - val_mae: 0.0376 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - loss: 0.0040 - mae: 0.0453 - val_loss: 0.0021 - val_mae: 0.0359 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0034 - mae: 0.0433 - val_loss: 0.0022 - val_mae: 0.0362 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - loss: 0.0040 - mae: 0.0435 - val_loss: 0.0023 - val_mae: 0.0364 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - loss: 0.0033 - mae: 0.0430 - val_loss: 0.0024 - val_mae: 0.0374 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - loss: 0.0032 - mae: 0.0429 - val_loss: 0.0024 - val_mae: 0.0380 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 144ms/step - loss: 0.0032 - mae: 0.0417 - val_loss: 0.0025 - val_mae: 0.0381 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0025 - val_mae: 0.0395 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0031 - mae: 0.0420 - val_loss: 0.0026 - val_mae: 0.0401 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001567. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
            "第 6 次實驗結果 (最後一項 Date_numeric: 20240424):\n",
            "LSTM模型預測結果: 0.5800963845103979%\n",
            "CNN+LSTM模型預測結果: 3.5367625951766968%\n",
            "隨機森林模型預測結果: -0.2734849781822266%\n",
            "SVR模型預測結果: -1.1021464044371307%\n",
            "XGBoost模型預測結果: -1.2316806241869926%\n",
            "Transformer模型預測結果: -1.3545110821723938%\n",
            "ARIMA+GARCH模型預測結果: [-0.93324755]%\n",
            "\n",
            "第 7 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 258ms/step - loss: 0.1134 - mae: 0.2574 - val_loss: 0.0237 - val_mae: 0.1440 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 217ms/step - loss: 0.0318 - mae: 0.1401 - val_loss: 0.0020 - val_mae: 0.0373 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 0.0143 - mae: 0.0930 - val_loss: 0.0017 - val_mae: 0.0339 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0065 - mae: 0.0635 - val_loss: 0.0016 - val_mae: 0.0318 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0018 - val_mae: 0.0338 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 0.0029 - mae: 0.0400 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0013 - val_mae: 0.0285 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 199ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0282 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 0.0013 - val_mae: 0.0282 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 219ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0013 - val_mae: 0.0287 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0285 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 0.0013 - val_mae: 0.0286 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 0.0019 - mae: 0.0277 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 259ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0013 - val_mae: 0.0285 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0013 - val_mae: 0.0285 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 0.1724 - mae: 0.3280 - val_loss: 0.0205 - val_mae: 0.1287 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 0.0290 - mae: 0.1308 - val_loss: 0.0175 - val_mae: 0.1231 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0081 - mae: 0.0689 - val_loss: 0.0167 - val_mae: 0.1201 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 141ms/step - loss: 0.0059 - mae: 0.0564 - val_loss: 0.0115 - val_mae: 0.0973 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 0.0046 - mae: 0.0508 - val_loss: 0.0038 - val_mae: 0.0512 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - loss: 0.0043 - mae: 0.0495 - val_loss: 0.0023 - val_mae: 0.0376 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - loss: 0.0038 - mae: 0.0456 - val_loss: 0.0023 - val_mae: 0.0380 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - loss: 0.0038 - mae: 0.0452 - val_loss: 0.0024 - val_mae: 0.0377 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 143ms/step - loss: 0.0040 - mae: 0.0432 - val_loss: 0.0034 - val_mae: 0.0464 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 0.0040 - mae: 0.0438 - val_loss: 0.0023 - val_mae: 0.0372 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 143ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0025 - val_mae: 0.0384 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - loss: 0.0032 - mae: 0.0423 - val_loss: 0.0028 - val_mae: 0.0417 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0030 - mae: 0.0407 - val_loss: 0.0028 - val_mae: 0.0414 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 142ms/step - loss: 0.0032 - mae: 0.0414 - val_loss: 0.0024 - val_mae: 0.0378 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 0.0032 - mae: 0.0408 - val_loss: 0.0030 - val_mae: 0.0428 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 0.0029 - val_mae: 0.0422 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001557. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
            "第 7 次實驗結果 (最後一項 Date_numeric: 20240617):\n",
            "LSTM模型預測結果: 0.9400425478816032%\n",
            "CNN+LSTM模型預測結果: 3.0750778317451477%\n",
            "隨機森林模型預測結果: -0.21523682307330277%\n",
            "SVR模型預測結果: -1.6910094879194142%\n",
            "XGBoost模型預測結果: 0.4584373440593481%\n",
            "Transformer模型預測結果: -0.43517574667930603%\n",
            "ARIMA+GARCH模型預測結果: [-0.7956325]%\n",
            "\n",
            "第 8 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 220ms/step - loss: 0.0741 - mae: 0.2162 - val_loss: 0.0024 - val_mae: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 238ms/step - loss: 0.0258 - mae: 0.1286 - val_loss: 0.0029 - val_mae: 0.0437 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 184ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0011 - val_mae: 0.0266 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0060 - mae: 0.0603 - val_loss: 9.1935e-04 - val_mae: 0.0228 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 8.5152e-04 - val_mae: 0.0216 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 7.6562e-04 - val_mae: 0.0220 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 219ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 8.6131e-04 - val_mae: 0.0239 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 7.1555e-04 - val_mae: 0.0202 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0017 - mae: 0.0296 - val_loss: 7.1551e-04 - val_mae: 0.0206 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 7.1627e-04 - val_mae: 0.0200 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 7.2061e-04 - val_mae: 0.0205 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 7.1562e-04 - val_mae: 0.0202 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 0.0018 - mae: 0.0276 - val_loss: 7.1487e-04 - val_mae: 0.0201 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 221ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 7.1344e-04 - val_mae: 0.0202 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 7.1415e-04 - val_mae: 0.0203 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 0.0019 - mae: 0.0278 - val_loss: 7.1192e-04 - val_mae: 0.0202 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 7.1187e-04 - val_mae: 0.0202 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 7.1223e-04 - val_mae: 0.0203 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 238ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 7.1217e-04 - val_mae: 0.0203 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 7.1247e-04 - val_mae: 0.0203 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.1291e-04 - val_mae: 0.0204 - learning_rate: 4.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 7.1230e-04 - val_mae: 0.0203 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0021 - mae: 0.0282 - val_loss: 7.1186e-04 - val_mae: 0.0203 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 7.1210e-04 - val_mae: 0.0203 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 7.1190e-04 - val_mae: 0.0203 - learning_rate: 8.0000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 7.1148e-04 - val_mae: 0.0203 - learning_rate: 8.0000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 198ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 7.1150e-04 - val_mae: 0.0203 - learning_rate: 1.6000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 7.1150e-04 - val_mae: 0.0203 - learning_rate: 1.6000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0020 - mae: 0.0280 - val_loss: 7.1153e-04 - val_mae: 0.0203 - learning_rate: 1.6000e-06\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 225ms/step - loss: 0.0022 - mae: 0.0285 - val_loss: 7.1155e-04 - val_mae: 0.0203 - learning_rate: 1.6000e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0019 - mae: 0.0285 - val_loss: 7.1157e-04 - val_mae: 0.0203 - learning_rate: 1.6000e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 7.1160e-04 - val_mae: 0.0203 - learning_rate: 1.0000e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 216ms/step - loss: 0.0022 - mae: 0.0280 - val_loss: 7.1161e-04 - val_mae: 0.0203 - learning_rate: 1.0000e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 260ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 7.1153e-04 - val_mae: 0.0203 - learning_rate: 1.0000e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 7.1161e-04 - val_mae: 0.0203 - learning_rate: 1.0000e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.1159e-04 - val_mae: 0.0203 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.1482 - mae: 0.3009 - val_loss: 0.0434 - val_mae: 0.2050 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - loss: 0.0347 - mae: 0.1422 - val_loss: 0.0016 - val_mae: 0.0304 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0070 - mae: 0.0645 - val_loss: 0.0348 - val_mae: 0.1831 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0061 - mae: 0.0574 - val_loss: 0.0192 - val_mae: 0.1336 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0065 - val_mae: 0.0738 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - loss: 0.0046 - mae: 0.0510 - val_loss: 0.0021 - val_mae: 0.0388 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0038 - mae: 0.0453 - val_loss: 0.0015 - val_mae: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0036 - mae: 0.0453 - val_loss: 0.0013 - val_mae: 0.0281 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.0025 - val_mae: 0.0392 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 0.0039 - mae: 0.0461 - val_loss: 0.0013 - val_mae: 0.0279 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - loss: 0.0038 - mae: 0.0443 - val_loss: 0.0013 - val_mae: 0.0262 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - loss: 0.0035 - mae: 0.0440 - val_loss: 0.0017 - val_mae: 0.0310 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0016 - val_mae: 0.0300 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0032 - mae: 0.0409 - val_loss: 0.0016 - val_mae: 0.0295 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - loss: 0.0031 - mae: 0.0393 - val_loss: 0.0018 - val_mae: 0.0323 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - loss: 0.0035 - mae: 0.0443 - val_loss: 0.0013 - val_mae: 0.0267 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0033 - mae: 0.0408 - val_loss: 0.0014 - val_mae: 0.0279 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0033 - mae: 0.0420 - val_loss: 0.0014 - val_mae: 0.0271 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - loss: 0.0031 - mae: 0.0391 - val_loss: 0.0014 - val_mae: 0.0278 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - loss: 0.0032 - mae: 0.0408 - val_loss: 0.0015 - val_mae: 0.0280 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - loss: 0.0030 - mae: 0.0408 - val_loss: 0.0015 - val_mae: 0.0280 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001581. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
            "第 8 次實驗結果 (最後一項 Date_numeric: 20231215):\n",
            "LSTM模型預測結果: 0.22577636409550905%\n",
            "CNN+LSTM模型預測結果: 2.72208034992218%\n",
            "隨機森林模型預測結果: 3.6122930547787986%\n",
            "SVR模型預測結果: 0.45640924067732935%\n",
            "XGBoost模型預測結果: -2.656303159892559%\n",
            "Transformer模型預測結果: 0.2831101417541504%\n",
            "ARIMA+GARCH模型預測結果: [1.42301482]%\n",
            "\n",
            "第 9 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 241ms/step - loss: 0.0913 - mae: 0.2311 - val_loss: 0.0215 - val_mae: 0.1380 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 231ms/step - loss: 0.0260 - mae: 0.1274 - val_loss: 0.0017 - val_mae: 0.0318 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 229ms/step - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0016 - val_mae: 0.0325 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 229ms/step - loss: 0.0049 - mae: 0.0553 - val_loss: 0.0015 - val_mae: 0.0291 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 231ms/step - loss: 0.0032 - mae: 0.0422 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 226ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 225ms/step - loss: 0.0020 - mae: 0.0324 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 225ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0293 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 228ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0289 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 229ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 227ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0014 - val_mae: 0.0292 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 227ms/step - loss: 0.0022 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0286 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 229ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0293 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 258ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 228ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 225ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 227ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0014 - val_mae: 0.0290 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 119ms/step - loss: 0.2110 - mae: 0.3643 - val_loss: 0.0278 - val_mae: 0.1543 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0607 - mae: 0.1903 - val_loss: 0.0067 - val_mae: 0.0698 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 0.0105 - mae: 0.0809 - val_loss: 0.0195 - val_mae: 0.1299 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - loss: 0.0054 - mae: 0.0566 - val_loss: 0.0096 - val_mae: 0.0860 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0046 - mae: 0.0527 - val_loss: 0.0052 - val_mae: 0.0607 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 0.0042 - mae: 0.0496 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 0.0039 - mae: 0.0472 - val_loss: 0.0024 - val_mae: 0.0374 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0038 - mae: 0.0468 - val_loss: 0.0026 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - loss: 0.0036 - mae: 0.0447 - val_loss: 0.0028 - val_mae: 0.0421 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 157ms/step - loss: 0.0037 - mae: 0.0452 - val_loss: 0.0025 - val_mae: 0.0391 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - loss: 0.0035 - mae: 0.0438 - val_loss: 0.0026 - val_mae: 0.0397 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0026 - val_mae: 0.0399 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 141ms/step - loss: 0.0033 - mae: 0.0429 - val_loss: 0.0025 - val_mae: 0.0390 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - loss: 0.0034 - mae: 0.0424 - val_loss: 0.0027 - val_mae: 0.0405 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0036 - mae: 0.0422 - val_loss: 0.0025 - val_mae: 0.0387 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 0.0036 - mae: 0.0429 - val_loss: 0.0028 - val_mae: 0.0418 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - loss: 0.0031 - mae: 0.0408 - val_loss: 0.0028 - val_mae: 0.0417 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001554. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 9 次實驗結果 (最後一項 Date_numeric: 20240718):\n",
            "LSTM模型預測結果: -0.05576438270509243%\n",
            "CNN+LSTM模型預測結果: 2.64243483543396%\n",
            "隨機森林模型預測結果: -2.4910665331827913%\n",
            "SVR模型預測結果: -3.2793446827643744%\n",
            "XGBoost模型預測結果: 3.628115728497505%\n",
            "Transformer模型預測結果: -1.7934966832399368%\n",
            "ARIMA+GARCH模型預測結果: [-2.96097363]%\n",
            "\n",
            "第 10 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 195ms/step - loss: 0.0785 - mae: 0.2175 - val_loss: 0.0134 - val_mae: 0.0961 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 0.0310 - mae: 0.1371 - val_loss: 0.0016 - val_mae: 0.0315 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0114 - mae: 0.0841 - val_loss: 9.5152e-04 - val_mae: 0.0241 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 181ms/step - loss: 0.0047 - mae: 0.0538 - val_loss: 7.8370e-04 - val_mae: 0.0213 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 210ms/step - loss: 0.0032 - mae: 0.0433 - val_loss: 8.6625e-04 - val_mae: 0.0237 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 7.3775e-04 - val_mae: 0.0204 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 189ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 7.5814e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 7.3168e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 7.3527e-04 - val_mae: 0.0202 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 189ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 7.3237e-04 - val_mae: 0.0205 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 210ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 7.3366e-04 - val_mae: 0.0206 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 7.3493e-04 - val_mae: 0.0207 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 211ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 7.3178e-04 - val_mae: 0.0205 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 185ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.3351e-04 - val_mae: 0.0206 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 7.3304e-04 - val_mae: 0.0206 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 225ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 7.3114e-04 - val_mae: 0.0204 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 205ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 7.3103e-04 - val_mae: 0.0204 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 7.3130e-04 - val_mae: 0.0204 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 7.3087e-04 - val_mae: 0.0204 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.0022 - mae: 0.0286 - val_loss: 7.3112e-04 - val_mae: 0.0204 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 7.3126e-04 - val_mae: 0.0204 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 7.3126e-04 - val_mae: 0.0204 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 7.3097e-04 - val_mae: 0.0204 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 7.3136e-04 - val_mae: 0.0205 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 258ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 7.3133e-04 - val_mae: 0.0204 - learning_rate: 1.6000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 219ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 7.3139e-04 - val_mae: 0.0205 - learning_rate: 1.6000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 7.3136e-04 - val_mae: 0.0204 - learning_rate: 1.6000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 192ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 7.3129e-04 - val_mae: 0.0204 - learning_rate: 1.6000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 213ms/step - loss: 0.0020 - mae: 0.0284 - val_loss: 7.3129e-04 - val_mae: 0.0204 - learning_rate: 1.6000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.1780 - mae: 0.3288 - val_loss: 0.0206 - val_mae: 0.1381 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - loss: 0.0315 - mae: 0.1365 - val_loss: 0.0094 - val_mae: 0.0910 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0077 - mae: 0.0683 - val_loss: 0.0301 - val_mae: 0.1694 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0059 - mae: 0.0586 - val_loss: 0.0176 - val_mae: 0.1275 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0051 - mae: 0.0543 - val_loss: 0.0094 - val_mae: 0.0907 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 0.0044 - mae: 0.0502 - val_loss: 0.0019 - val_mae: 0.0367 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - loss: 0.0040 - mae: 0.0463 - val_loss: 0.0018 - val_mae: 0.0347 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - loss: 0.0040 - mae: 0.0468 - val_loss: 0.0018 - val_mae: 0.0327 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0039 - mae: 0.0464 - val_loss: 0.0013 - val_mae: 0.0270 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0013 - val_mae: 0.0270 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - loss: 0.0032 - mae: 0.0422 - val_loss: 0.0026 - val_mae: 0.0407 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - loss: 0.0037 - mae: 0.0425 - val_loss: 0.0028 - val_mae: 0.0436 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - loss: 0.0032 - mae: 0.0413 - val_loss: 0.0032 - val_mae: 0.0477 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 0.0036 - mae: 0.0415 - val_loss: 0.0016 - val_mae: 0.0310 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - loss: 0.0032 - mae: 0.0412 - val_loss: 0.0019 - val_mae: 0.0347 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.0022 - val_mae: 0.0381 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0023 - val_mae: 0.0386 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0031 - mae: 0.0391 - val_loss: 0.0021 - val_mae: 0.0366 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0034 - mae: 0.0403 - val_loss: 0.0024 - val_mae: 0.0393 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - loss: 0.0032 - mae: 0.0398 - val_loss: 0.0025 - val_mae: 0.0401 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001577. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
            "第 10 次實驗結果 (最後一項 Date_numeric: 20231228):\n",
            "LSTM模型預測結果: 0.4119850695133209%\n",
            "CNN+LSTM模型預測結果: 3.45639169216156%\n",
            "隨機森林模型預測結果: 0.37327334701595977%\n",
            "SVR模型預測結果: 1.386147564774061%\n",
            "XGBoost模型預測結果: 0.32183914445340633%\n",
            "Transformer模型預測結果: 2.1809227764606476%\n",
            "ARIMA+GARCH模型預測結果: [1.10894871]%\n",
            "\n",
            "第 11 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 199ms/step - loss: 0.0868 - mae: 0.2311 - val_loss: 0.0028 - val_mae: 0.0426 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0293 - mae: 0.1347 - val_loss: 0.0021 - val_mae: 0.0368 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0117 - mae: 0.0825 - val_loss: 0.0018 - val_mae: 0.0326 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0061 - mae: 0.0597 - val_loss: 0.0018 - val_mae: 0.0327 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0014 - val_mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 211ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0014 - val_mae: 0.0285 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 213ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0015 - val_mae: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step - loss: 0.0020 - mae: 0.0319 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 257ms/step - loss: 0.0018 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 220ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 0.0013 - val_mae: 0.0285 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 188ms/step - loss: 0.0020 - mae: 0.0279 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 0.0019 - mae: 0.0284 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 213ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - loss: 0.1926 - mae: 0.3360 - val_loss: 0.0037 - val_mae: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 147ms/step - loss: 0.0434 - mae: 0.1584 - val_loss: 0.0077 - val_mae: 0.0760 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - loss: 0.0095 - mae: 0.0748 - val_loss: 0.0253 - val_mae: 0.1517 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.0047 - mae: 0.0530 - val_loss: 0.0120 - val_mae: 0.0994 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 150ms/step - loss: 0.0046 - mae: 0.0527 - val_loss: 0.0043 - val_mae: 0.0544 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - loss: 0.0048 - mae: 0.0505 - val_loss: 0.0048 - val_mae: 0.0583 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.0044 - mae: 0.0480 - val_loss: 0.0029 - val_mae: 0.0428 - learning_rate: 2.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 153ms/step - loss: 0.0041 - mae: 0.0475 - val_loss: 0.0024 - val_mae: 0.0383 - learning_rate: 2.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.0038 - mae: 0.0458 - val_loss: 0.0024 - val_mae: 0.0381 - learning_rate: 2.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 0.0035 - mae: 0.0448 - val_loss: 0.0023 - val_mae: 0.0379 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - loss: 0.0040 - mae: 0.0456 - val_loss: 0.0024 - val_mae: 0.0382 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 151ms/step - loss: 0.0040 - mae: 0.0466 - val_loss: 0.0023 - val_mae: 0.0379 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.0041 - mae: 0.0461 - val_loss: 0.0023 - val_mae: 0.0381 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 153ms/step - loss: 0.0038 - mae: 0.0474 - val_loss: 0.0024 - val_mae: 0.0380 - learning_rate: 4.0000e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 0.0040 - mae: 0.0455 - val_loss: 0.0024 - val_mae: 0.0380 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 116ms/step - loss: 0.0035 - mae: 0.0450 - val_loss: 0.0024 - val_mae: 0.0380 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 0.0037 - mae: 0.0448 - val_loss: 0.0024 - val_mae: 0.0379 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 136ms/step - loss: 0.0041 - mae: 0.0456 - val_loss: 0.0024 - val_mae: 0.0380 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.0035 - mae: 0.0440 - val_loss: 0.0024 - val_mae: 0.0379 - learning_rate: 8.0000e-06\n",
            "Epoch 20/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 152ms/step - loss: 0.0036 - mae: 0.0438 - val_loss: 0.0024 - val_mae: 0.0379 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.0034 - mae: 0.0443 - val_loss: 0.0024 - val_mae: 0.0379 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 0.0024 - val_mae: 0.0379 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001558. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 11 次實驗結果 (最後一項 Date_numeric: 20240614):\n",
            "LSTM模型預測結果: 0.17417140770703554%\n",
            "CNN+LSTM模型預測結果: 2.997226119041443%\n",
            "隨機森林模型預測結果: -0.8242025084557032%\n",
            "SVR模型預測結果: -1.1549647145020172%\n",
            "XGBoost模型預測結果: -2.50017698854208%\n",
            "Transformer模型預測結果: 0.8904151618480682%\n",
            "ARIMA+GARCH模型預測結果: [-0.63167522]%\n",
            "\n",
            "第 12 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 232ms/step - loss: 0.0796 - mae: 0.2225 - val_loss: 0.0089 - val_mae: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 257ms/step - loss: 0.0292 - mae: 0.1329 - val_loss: 0.0023 - val_mae: 0.0409 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 220ms/step - loss: 0.0129 - mae: 0.0885 - val_loss: 0.0011 - val_mae: 0.0250 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0056 - mae: 0.0581 - val_loss: 8.6848e-04 - val_mae: 0.0227 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0033 - mae: 0.0446 - val_loss: 9.2070e-04 - val_mae: 0.0240 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 8.5011e-04 - val_mae: 0.0224 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0023 - mae: 0.0335 - val_loss: 8.2152e-04 - val_mae: 0.0215 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 8.2094e-04 - val_mae: 0.0218 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 222ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 8.1219e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 8.1246e-04 - val_mae: 0.0214 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 8.1176e-04 - val_mae: 0.0215 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.1094e-04 - val_mae: 0.0214 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 8.1109e-04 - val_mae: 0.0215 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0020 - mae: 0.0281 - val_loss: 8.1129e-04 - val_mae: 0.0214 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 8.1137e-04 - val_mae: 0.0215 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 8.1115e-04 - val_mae: 0.0215 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0018 - mae: 0.0279 - val_loss: 8.1093e-04 - val_mae: 0.0215 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 8.1072e-04 - val_mae: 0.0214 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 195ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 8.1057e-04 - val_mae: 0.0214 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 8.1055e-04 - val_mae: 0.0214 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 222ms/step - loss: 0.0019 - mae: 0.0292 - val_loss: 8.1053e-04 - val_mae: 0.0214 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 8.1045e-04 - val_mae: 0.0214 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 8.1040e-04 - val_mae: 0.0214 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 192ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 8.1036e-04 - val_mae: 0.0214 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 220ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 8.1038e-04 - val_mae: 0.0214 - learning_rate: 1.6000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 8.1041e-04 - val_mae: 0.0214 - learning_rate: 1.6000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 8.1043e-04 - val_mae: 0.0214 - learning_rate: 1.6000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 225ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 8.1040e-04 - val_mae: 0.0214 - learning_rate: 1.6000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 8.1036e-04 - val_mae: 0.0214 - learning_rate: 1.6000e-06\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 8.1037e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 264ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 8.1037e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 8.1037e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 8.1032e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 230ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 8.1034e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 8.1036e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0020 - mae: 0.0276 - val_loss: 8.1037e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 8.1037e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 8.1038e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 8.1036e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.1032e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 8.1032e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 8.1033e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 8.1033e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 8.1034e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 8.1034e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 8.1037e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.1034e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.1028e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 8.1035e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 8.1036e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.1033e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 8.1032e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 8.1033e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 8.1032e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 216ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 8.1030e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 192ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 8.1031e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.1028e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 253ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 8.1029e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 8.1031e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 184ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.1024e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 221ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 8.1018e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 8.1027e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 188ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 8.1028e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 8.1028e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 8.1028e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 8.1019e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 8.1021e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 8.1017e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 190ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 8.1016e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 224ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 8.1018e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 250ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 8.1015e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 185ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 8.1016e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 216ms/step - loss: 0.0018 - mae: 0.0285 - val_loss: 8.1023e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 8.1023e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 8.1021e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - loss: 0.0018 - mae: 0.0276 - val_loss: 8.1018e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 224ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 8.1019e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 8.1016e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 8.1021e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 8.1018e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.1015e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 8.1010e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 222ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 8.1005e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0019 - mae: 0.0280 - val_loss: 8.1013e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0020 - mae: 0.0285 - val_loss: 8.1013e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 262ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 8.1010e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 8.1009e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 8.1008e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 8.1005e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 8.1010e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 0.0019 - mae: 0.0280 - val_loss: 8.1004e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 8.1004e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 221ms/step - loss: 0.0021 - mae: 0.0282 - val_loss: 8.1003e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 0.0019 - mae: 0.0283 - val_loss: 8.1004e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 8.1003e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0019 - mae: 0.0274 - val_loss: 8.1004e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 194ms/step - loss: 0.0018 - mae: 0.0285 - val_loss: 8.1001e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 0.0022 - mae: 0.0291 - val_loss: 8.0999e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 228ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 8.1005e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 222ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 8.1008e-04 - val_mae: 0.0214 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - loss: 0.1984 - mae: 0.3515 - val_loss: 0.0522 - val_mae: 0.2251 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 118ms/step - loss: 0.0542 - mae: 0.1813 - val_loss: 0.0249 - val_mae: 0.1507 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0103 - mae: 0.0791 - val_loss: 0.0091 - val_mae: 0.0853 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 143ms/step - loss: 0.0053 - mae: 0.0567 - val_loss: 0.0142 - val_mae: 0.1125 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0044 - mae: 0.0512 - val_loss: 0.0088 - val_mae: 0.0869 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 142ms/step - loss: 0.0043 - mae: 0.0499 - val_loss: 0.0025 - val_mae: 0.0422 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0042 - mae: 0.0489 - val_loss: 0.0018 - val_mae: 0.0348 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0037 - mae: 0.0461 - val_loss: 0.0017 - val_mae: 0.0324 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 0.0015 - val_mae: 0.0294 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - loss: 0.0035 - mae: 0.0446 - val_loss: 0.0015 - val_mae: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0038 - mae: 0.0453 - val_loss: 0.0018 - val_mae: 0.0325 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0037 - mae: 0.0440 - val_loss: 0.0019 - val_mae: 0.0339 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - loss: 0.0033 - mae: 0.0427 - val_loss: 0.0016 - val_mae: 0.0306 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0022 - val_mae: 0.0369 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0035 - mae: 0.0428 - val_loss: 0.0015 - val_mae: 0.0293 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0017 - val_mae: 0.0312 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0019 - val_mae: 0.0339 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - loss: 0.0029 - mae: 0.0400 - val_loss: 0.0019 - val_mae: 0.0339 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0019 - val_mae: 0.0334 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001578. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
            "第 12 次實驗結果 (最後一項 Date_numeric: 20240124):\n",
            "LSTM模型預測結果: 0.06094698910601437%\n",
            "CNN+LSTM模型預測結果: 2.7041172981262207%\n",
            "隨機森林模型預測結果: -0.28032720904863456%\n",
            "SVR模型預測結果: 5.119508272428795%\n",
            "XGBoost模型預測結果: -2.134512737393379%\n",
            "Transformer模型預測結果: 5.193406715989113%\n",
            "ARIMA+GARCH模型預測結果: [2.19072978]%\n",
            "\n",
            "第 13 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 260ms/step - loss: 0.0667 - mae: 0.2028 - val_loss: 0.0387 - val_mae: 0.1878 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - loss: 0.0218 - mae: 0.1158 - val_loss: 0.0029 - val_mae: 0.0456 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.0088 - mae: 0.0723 - val_loss: 9.8443e-04 - val_mae: 0.0243 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 199ms/step - loss: 0.0045 - mae: 0.0506 - val_loss: 7.6862e-04 - val_mae: 0.0210 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 198ms/step - loss: 0.0025 - mae: 0.0369 - val_loss: 7.5683e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 7.3744e-04 - val_mae: 0.0209 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 0.0021 - mae: 0.0310 - val_loss: 7.3765e-04 - val_mae: 0.0204 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 219ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 7.5447e-04 - val_mae: 0.0215 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 221ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 7.6226e-04 - val_mae: 0.0217 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 222ms/step - loss: 0.0020 - mae: 0.0283 - val_loss: 7.4094e-04 - val_mae: 0.0208 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 7.4597e-04 - val_mae: 0.0211 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 7.4186e-04 - val_mae: 0.0207 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 7.4048e-04 - val_mae: 0.0208 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 7.4662e-04 - val_mae: 0.0212 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 257ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 7.4350e-04 - val_mae: 0.0210 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 220ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 7.4314e-04 - val_mae: 0.0210 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 149ms/step - loss: 0.1523 - mae: 0.3072 - val_loss: 0.0239 - val_mae: 0.1470 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0320 - mae: 0.1408 - val_loss: 0.0195 - val_mae: 0.1312 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0074 - mae: 0.0644 - val_loss: 0.0019 - val_mae: 0.0344 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - loss: 0.0053 - mae: 0.0565 - val_loss: 0.0023 - val_mae: 0.0403 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0045 - mae: 0.0522 - val_loss: 0.0014 - val_mae: 0.0279 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0015 - val_mae: 0.0288 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - loss: 0.0043 - mae: 0.0491 - val_loss: 0.0013 - val_mae: 0.0270 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - loss: 0.0038 - mae: 0.0474 - val_loss: 0.0015 - val_mae: 0.0287 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0038 - mae: 0.0460 - val_loss: 0.0020 - val_mae: 0.0354 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - loss: 0.0046 - mae: 0.0467 - val_loss: 0.0020 - val_mae: 0.0351 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - loss: 0.0038 - mae: 0.0431 - val_loss: 0.0020 - val_mae: 0.0356 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0021 - val_mae: 0.0360 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - loss: 0.0041 - mae: 0.0451 - val_loss: 0.0019 - val_mae: 0.0341 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.0038 - mae: 0.0436 - val_loss: 0.0020 - val_mae: 0.0359 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0016 - val_mae: 0.0304 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 0.0019 - val_mae: 0.0338 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - loss: 0.0032 - mae: 0.0413 - val_loss: 0.0017 - val_mae: 0.0323 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001578. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
            "第 13 次實驗結果 (最後一項 Date_numeric: 20240103):\n",
            "LSTM模型預測結果: 0.21201451309025288%\n",
            "CNN+LSTM模型預測結果: 3.1181561946868896%\n",
            "隨機森林模型預測結果: 0.3738952604875771%\n",
            "SVR模型預測結果: -3.1551976003754034%\n",
            "XGBoost模型預測結果: -4.559477046132088%\n",
            "Transformer模型預測結果: -1.2059969827532768%\n",
            "ARIMA+GARCH模型預測結果: [-0.62443357]%\n",
            "\n",
            "第 14 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 293ms/step - loss: 0.1332 - mae: 0.2798 - val_loss: 0.0029 - val_mae: 0.0433 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 233ms/step - loss: 0.0355 - mae: 0.1446 - val_loss: 0.0022 - val_mae: 0.0380 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 231ms/step - loss: 0.0162 - mae: 0.0997 - val_loss: 0.0019 - val_mae: 0.0353 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 226ms/step - loss: 0.0074 - mae: 0.0646 - val_loss: 0.0016 - val_mae: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 225ms/step - loss: 0.0040 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0292 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0014 - val_mae: 0.0286 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 234ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 232ms/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.0015 - val_mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 233ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0293 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 238ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 233ms/step - loss: 0.0021 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0286 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 230ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 241ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0286 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 234ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 0.0013 - val_mae: 0.0285 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 229ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0285 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 228ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 0.0013 - val_mae: 0.0284 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 228ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 230ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 237ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 231ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 8.0000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 1.6000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 242ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 1.6000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 254ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 1.6000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 230ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0283 - learning_rate: 1.6000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 159ms/step - loss: 0.1523 - mae: 0.3052 - val_loss: 0.0273 - val_mae: 0.1580 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - loss: 0.0285 - mae: 0.1303 - val_loss: 0.0026 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 0.0071 - mae: 0.0643 - val_loss: 0.0295 - val_mae: 0.1648 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 0.0144 - val_mae: 0.1107 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0044 - mae: 0.0519 - val_loss: 0.0045 - val_mae: 0.0561 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0041 - mae: 0.0471 - val_loss: 0.0027 - val_mae: 0.0418 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 155ms/step - loss: 0.0038 - mae: 0.0465 - val_loss: 0.0023 - val_mae: 0.0378 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.0037 - mae: 0.0441 - val_loss: 0.0023 - val_mae: 0.0369 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 0.0040 - mae: 0.0453 - val_loss: 0.0026 - val_mae: 0.0403 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 0.0032 - mae: 0.0423 - val_loss: 0.0024 - val_mae: 0.0382 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 118ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0027 - val_mae: 0.0413 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 0.0032 - mae: 0.0415 - val_loss: 0.0026 - val_mae: 0.0399 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - loss: 0.0033 - mae: 0.0411 - val_loss: 0.0027 - val_mae: 0.0407 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.0031 - mae: 0.0406 - val_loss: 0.0027 - val_mae: 0.0411 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0033 - mae: 0.0408 - val_loss: 0.0026 - val_mae: 0.0395 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 154ms/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0026 - val_mae: 0.0396 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - loss: 0.0040 - mae: 0.0421 - val_loss: 0.0026 - val_mae: 0.0402 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001556. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
            "第 14 次實驗結果 (最後一項 Date_numeric: 20240624):\n",
            "LSTM模型預測結果: 0.19379014847800136%\n",
            "CNN+LSTM模型預測結果: 3.0831748247146606%\n",
            "隨機森林模型預測結果: -1.5512050429645798%\n",
            "SVR模型預測結果: -1.2441575006155492%\n",
            "XGBoost模型預測結果: -1.1681737378239632%\n",
            "Transformer模型預測結果: -0.941023975610733%\n",
            "ARIMA+GARCH模型預測結果: [0.01938061]%\n",
            "\n",
            "第 15 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 233ms/step - loss: 0.0657 - mae: 0.1984 - val_loss: 0.0107 - val_mae: 0.0899 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - loss: 0.0208 - mae: 0.1119 - val_loss: 0.0023 - val_mae: 0.0411 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 201ms/step - loss: 0.0108 - mae: 0.0790 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - loss: 0.0047 - mae: 0.0530 - val_loss: 9.3903e-04 - val_mae: 0.0222 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0030 - mae: 0.0409 - val_loss: 9.4758e-04 - val_mae: 0.0239 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0021 - mae: 0.0348 - val_loss: 9.7777e-04 - val_mae: 0.0244 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 188ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 9.0275e-04 - val_mae: 0.0231 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 219ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 8.9621e-04 - val_mae: 0.0227 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 8.9394e-04 - val_mae: 0.0224 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 8.9966e-04 - val_mae: 0.0227 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 9.0676e-04 - val_mae: 0.0230 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 8.9373e-04 - val_mae: 0.0223 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 8.9365e-04 - val_mae: 0.0224 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0020 - mae: 0.0278 - val_loss: 8.9824e-04 - val_mae: 0.0227 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 8.9811e-04 - val_mae: 0.0227 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 8.9887e-04 - val_mae: 0.0227 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 8.9896e-04 - val_mae: 0.0227 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 231ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 8.9458e-04 - val_mae: 0.0225 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 231ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 8.9750e-04 - val_mae: 0.0227 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 8.9701e-04 - val_mae: 0.0226 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 211ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.9687e-04 - val_mae: 0.0226 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 8.9701e-04 - val_mae: 0.0226 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 223ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 8.9635e-04 - val_mae: 0.0226 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 149ms/step - loss: 0.2001 - mae: 0.3444 - val_loss: 0.0526 - val_mae: 0.2225 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0461 - mae: 0.1679 - val_loss: 0.0175 - val_mae: 0.1243 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 0.0088 - mae: 0.0726 - val_loss: 0.0142 - val_mae: 0.1115 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - loss: 0.0055 - mae: 0.0573 - val_loss: 0.0135 - val_mae: 0.1084 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0079 - val_mae: 0.0809 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - loss: 0.0040 - mae: 0.0478 - val_loss: 0.0024 - val_mae: 0.0404 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - loss: 0.0045 - mae: 0.0474 - val_loss: 0.0017 - val_mae: 0.0310 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.0037 - mae: 0.0455 - val_loss: 0.0017 - val_mae: 0.0305 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0040 - mae: 0.0469 - val_loss: 0.0016 - val_mae: 0.0298 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0036 - mae: 0.0456 - val_loss: 0.0017 - val_mae: 0.0308 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0016 - val_mae: 0.0297 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0039 - mae: 0.0456 - val_loss: 0.0016 - val_mae: 0.0299 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0020 - val_mae: 0.0349 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 0.0044 - mae: 0.0439 - val_loss: 0.0016 - val_mae: 0.0304 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 0.0030 - mae: 0.0411 - val_loss: 0.0017 - val_mae: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0021 - val_mae: 0.0357 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0019 - val_mae: 0.0338 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0032 - mae: 0.0402 - val_loss: 0.0021 - val_mae: 0.0366 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - loss: 0.0038 - mae: 0.0418 - val_loss: 0.0019 - val_mae: 0.0343 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 149ms/step - loss: 0.0035 - mae: 0.0407 - val_loss: 0.0019 - val_mae: 0.0340 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0029 - mae: 0.0397 - val_loss: 0.0021 - val_mae: 0.0360 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 141ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0020 - val_mae: 0.0351 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001573. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 15 次實驗結果 (最後一項 Date_numeric: 20240213):\n",
            "LSTM模型預測結果: 0.32318057492375374%\n",
            "CNN+LSTM模型預測結果: 3.8982874155044556%\n",
            "隨機森林模型預測結果: -3.194556812604942%\n",
            "SVR模型預測結果: -0.9438362298547298%\n",
            "XGBoost模型預測結果: 0.6474578753113747%\n",
            "Transformer模型預測結果: -0.0627344474196434%\n",
            "ARIMA+GARCH模型預測結果: [-0.21898102]%\n",
            "\n",
            "第 16 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 207ms/step - loss: 0.1089 - mae: 0.2573 - val_loss: 0.0131 - val_mae: 0.0897 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - loss: 0.0413 - mae: 0.1600 - val_loss: 0.0029 - val_mae: 0.0427 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 240ms/step - loss: 0.0172 - mae: 0.1041 - val_loss: 0.0017 - val_mae: 0.0333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 218ms/step - loss: 0.0079 - mae: 0.0681 - val_loss: 0.0013 - val_mae: 0.0282 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 0.0040 - mae: 0.0479 - val_loss: 0.0011 - val_mae: 0.0260 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0012 - val_mae: 0.0277 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 219ms/step - loss: 0.0025 - mae: 0.0367 - val_loss: 0.0011 - val_mae: 0.0260 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0264 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 0.0024 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0252 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0256 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0252 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0023 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0253 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0018 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - loss: 0.0022 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 0.2094 - mae: 0.3555 - val_loss: 0.0655 - val_mae: 0.2516 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 0.0433 - mae: 0.1597 - val_loss: 0.0102 - val_mae: 0.0901 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0085 - mae: 0.0712 - val_loss: 0.0201 - val_mae: 0.1348 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0058 - mae: 0.0575 - val_loss: 0.0163 - val_mae: 0.1206 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - loss: 0.0048 - mae: 0.0533 - val_loss: 0.0043 - val_mae: 0.0560 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - loss: 0.0045 - mae: 0.0507 - val_loss: 0.0025 - val_mae: 0.0408 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 144ms/step - loss: 0.0043 - mae: 0.0492 - val_loss: 0.0020 - val_mae: 0.0357 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - loss: 0.0038 - mae: 0.0474 - val_loss: 0.0020 - val_mae: 0.0345 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 148ms/step - loss: 0.0041 - mae: 0.0463 - val_loss: 0.0019 - val_mae: 0.0334 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0020 - val_mae: 0.0338 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0035 - mae: 0.0445 - val_loss: 0.0019 - val_mae: 0.0330 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 0.0027 - val_mae: 0.0415 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.0041 - mae: 0.0422 - val_loss: 0.0034 - val_mae: 0.0477 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 147ms/step - loss: 0.0037 - mae: 0.0431 - val_loss: 0.0024 - val_mae: 0.0384 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 129ms/step - loss: 0.0033 - mae: 0.0402 - val_loss: 0.0026 - val_mae: 0.0406 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0021 - val_mae: 0.0353 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - loss: 0.0027 - mae: 0.0379 - val_loss: 0.0022 - val_mae: 0.0364 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0025 - val_mae: 0.0395 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0035 - mae: 0.0395 - val_loss: 0.0024 - val_mae: 0.0386 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0023 - val_mae: 0.0371 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 135ms/step - loss: 0.0028 - mae: 0.0380 - val_loss: 0.0024 - val_mae: 0.0383 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001574. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 16 次實驗結果 (最後一項 Date_numeric: 20240318):\n",
            "LSTM模型預測結果: 0.150051258970052%\n",
            "CNN+LSTM模型預測結果: 2.688491642475128%\n",
            "隨機森林模型預測結果: 2.3203109720561486%\n",
            "SVR模型預測結果: -1.3829476782732433%\n",
            "XGBoost模型預測結果: -0.7272612769156694%\n",
            "Transformer模型預測結果: 2.0911812782287598%\n",
            "ARIMA+GARCH模型預測結果: [-0.98811211]%\n",
            "\n",
            "第 17 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 229ms/step - loss: 0.1032 - mae: 0.2507 - val_loss: 0.0220 - val_mae: 0.1231 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - loss: 0.0352 - mae: 0.1467 - val_loss: 0.0031 - val_mae: 0.0426 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 0.0153 - mae: 0.0956 - val_loss: 0.0013 - val_mae: 0.0272 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 237ms/step - loss: 0.0075 - mae: 0.0663 - val_loss: 0.0013 - val_mae: 0.0288 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 217ms/step - loss: 0.0033 - mae: 0.0432 - val_loss: 0.0012 - val_mae: 0.0287 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0011 - val_mae: 0.0264 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 0.0013 - val_mae: 0.0287 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0023 - mae: 0.0307 - val_loss: 0.0011 - val_mae: 0.0263 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0272 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 211ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0267 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0263 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0261 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0266 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0260 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 252ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 198ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 4.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0017 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 222ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 8.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 169ms/step - loss: 0.1828 - mae: 0.3382 - val_loss: 0.0058 - val_mae: 0.0647 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - loss: 0.0371 - mae: 0.1483 - val_loss: 0.0193 - val_mae: 0.1311 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0278 - val_mae: 0.1606 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 157ms/step - loss: 0.0054 - mae: 0.0576 - val_loss: 0.0106 - val_mae: 0.0940 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 0.0045 - mae: 0.0505 - val_loss: 0.0049 - val_mae: 0.0595 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 140ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 0.0028 - val_mae: 0.0433 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 156ms/step - loss: 0.0042 - mae: 0.0487 - val_loss: 0.0025 - val_mae: 0.0411 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - loss: 0.0045 - mae: 0.0488 - val_loss: 0.0024 - val_mae: 0.0387 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - loss: 0.0035 - mae: 0.0441 - val_loss: 0.0023 - val_mae: 0.0377 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 0.0048 - mae: 0.0462 - val_loss: 0.0020 - val_mae: 0.0346 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 154ms/step - loss: 0.0037 - mae: 0.0418 - val_loss: 0.0025 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 129ms/step - loss: 0.0029 - mae: 0.0401 - val_loss: 0.0034 - val_mae: 0.0470 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - loss: 0.0041 - mae: 0.0433 - val_loss: 0.0021 - val_mae: 0.0354 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 0.0030 - mae: 0.0399 - val_loss: 0.0019 - val_mae: 0.0342 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - loss: 0.0033 - mae: 0.0420 - val_loss: 0.0024 - val_mae: 0.0389 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - loss: 0.0028 - mae: 0.0384 - val_loss: 0.0024 - val_mae: 0.0385 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - loss: 0.0034 - mae: 0.0397 - val_loss: 0.0024 - val_mae: 0.0388 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 155ms/step - loss: 0.0026 - mae: 0.0382 - val_loss: 0.0024 - val_mae: 0.0391 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - loss: 0.0032 - mae: 0.0403 - val_loss: 0.0023 - val_mae: 0.0380 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0026 - val_mae: 0.0404 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 153ms/step - loss: 0.0033 - mae: 0.0400 - val_loss: 0.0024 - val_mae: 0.0387 - learning_rate: 4.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - loss: 0.0037 - mae: 0.0405 - val_loss: 0.0024 - val_mae: 0.0388 - learning_rate: 4.0000e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0024 - val_mae: 0.0388 - learning_rate: 4.0000e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 0.0036 - mae: 0.0401 - val_loss: 0.0025 - val_mae: 0.0398 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001569. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n",
            "第 17 次實驗結果 (最後一項 Date_numeric: 20240503):\n",
            "LSTM模型預測結果: -0.040577357867732644%\n",
            "CNN+LSTM模型預測結果: 3.3843541145324707%\n",
            "隨機森林模型預測結果: 5.746887141328028%\n",
            "SVR模型預測結果: 2.3194507494098944%\n",
            "XGBoost模型預測結果: 6.606890261173248%\n",
            "Transformer模型預測結果: 3.3208586275577545%\n",
            "ARIMA+GARCH模型預測結果: [0.14236287]%\n",
            "\n",
            "第 18 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 281ms/step - loss: 0.1134 - mae: 0.2684 - val_loss: 0.0108 - val_mae: 0.0868 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 234ms/step - loss: 0.0376 - mae: 0.1512 - val_loss: 0.0097 - val_mae: 0.0841 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 235ms/step - loss: 0.0156 - mae: 0.0965 - val_loss: 0.0017 - val_mae: 0.0335 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 237ms/step - loss: 0.0063 - mae: 0.0618 - val_loss: 0.0015 - val_mae: 0.0318 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 236ms/step - loss: 0.0037 - mae: 0.0455 - val_loss: 0.0015 - val_mae: 0.0309 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 229ms/step - loss: 0.0026 - mae: 0.0378 - val_loss: 0.0014 - val_mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 236ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0014 - val_mae: 0.0298 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 235ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0014 - val_mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 225ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 233ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0298 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 282ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0299 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 234ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0014 - val_mae: 0.0301 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 227ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0014 - val_mae: 0.0299 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 238ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 155ms/step - loss: 0.1812 - mae: 0.3298 - val_loss: 0.0046 - val_mae: 0.0554 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 0.0297 - mae: 0.1343 - val_loss: 0.0405 - val_mae: 0.1937 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0072 - mae: 0.0657 - val_loss: 0.0509 - val_mae: 0.2197 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0056 - mae: 0.0552 - val_loss: 0.0242 - val_mae: 0.1471 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0092 - val_mae: 0.0849 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - loss: 0.0047 - mae: 0.0499 - val_loss: 0.0036 - val_mae: 0.0502 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - loss: 0.0038 - mae: 0.0470 - val_loss: 0.0025 - val_mae: 0.0402 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0025 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 0.0034 - mae: 0.0439 - val_loss: 0.0025 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - loss: 0.0038 - mae: 0.0434 - val_loss: 0.0025 - val_mae: 0.0397 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step - loss: 0.0029 - mae: 0.0408 - val_loss: 0.0025 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - loss: 0.0031 - mae: 0.0418 - val_loss: 0.0026 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0035 - mae: 0.0417 - val_loss: 0.0026 - val_mae: 0.0399 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 183ms/step - loss: 0.0031 - mae: 0.0419 - val_loss: 0.0026 - val_mae: 0.0396 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 121ms/step - loss: 0.0032 - mae: 0.0419 - val_loss: 0.0027 - val_mae: 0.0402 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0030 - mae: 0.0407 - val_loss: 0.0030 - val_mae: 0.0432 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 0.0031 - mae: 0.0414 - val_loss: 0.0028 - val_mae: 0.0416 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - loss: 0.0034 - mae: 0.0395 - val_loss: 0.0027 - val_mae: 0.0409 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001552. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
            "第 18 次實驗結果 (最後一項 Date_numeric: 20240813):\n",
            "LSTM模型預測結果: 0.37773873191326857%\n",
            "CNN+LSTM模型預測結果: 3.0743619799613953%\n",
            "隨機森林模型預測結果: 0.16438117551847842%\n",
            "SVR模型預測結果: 2.434987784315378%\n",
            "XGBoost模型預測結果: -0.8010100573301315%\n",
            "Transformer模型預測結果: 2.8332985937595367%\n",
            "ARIMA+GARCH模型預測結果: [1.08137581]%\n",
            "\n",
            "第 19 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 233ms/step - loss: 0.0775 - mae: 0.2133 - val_loss: 0.0028 - val_mae: 0.0420 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 219ms/step - loss: 0.0224 - mae: 0.1184 - val_loss: 0.0022 - val_mae: 0.0397 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 199ms/step - loss: 0.0104 - mae: 0.0797 - val_loss: 0.0016 - val_mae: 0.0312 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 199ms/step - loss: 0.0052 - mae: 0.0567 - val_loss: 0.0011 - val_mae: 0.0270 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 0.0031 - mae: 0.0410 - val_loss: 0.0011 - val_mae: 0.0256 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0011 - val_mae: 0.0256 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 0.0020 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0256 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 251ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0252 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 221ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0253 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0252 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0250 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0250 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 0.0011 - val_mae: 0.0257 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0252 - learning_rate: 4.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 190ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 220ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 198ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 8.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 8.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0016 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 8.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 8.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 8.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - loss: 0.0014 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.6000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.6000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.6000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - loss: 0.0018 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.6000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.6000e-06\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 201ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 258ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0018 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 216ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 157ms/step - loss: 0.1845 - mae: 0.3358 - val_loss: 0.0525 - val_mae: 0.2245 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0359 - mae: 0.1459 - val_loss: 0.0066 - val_mae: 0.0667 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0082 - mae: 0.0706 - val_loss: 0.0094 - val_mae: 0.0859 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0052 - mae: 0.0543 - val_loss: 0.0079 - val_mae: 0.0792 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 0.0044 - mae: 0.0500 - val_loss: 0.0046 - val_mae: 0.0578 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.0043 - mae: 0.0500 - val_loss: 0.0023 - val_mae: 0.0390 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0038 - mae: 0.0467 - val_loss: 0.0018 - val_mae: 0.0333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0041 - mae: 0.0456 - val_loss: 0.0019 - val_mae: 0.0341 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - loss: 0.0035 - mae: 0.0444 - val_loss: 0.0019 - val_mae: 0.0339 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 148ms/step - loss: 0.0039 - mae: 0.0448 - val_loss: 0.0019 - val_mae: 0.0341 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - loss: 0.0033 - mae: 0.0419 - val_loss: 0.0018 - val_mae: 0.0328 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0036 - mae: 0.0438 - val_loss: 0.0018 - val_mae: 0.0331 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0019 - val_mae: 0.0331 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.0031 - mae: 0.0399 - val_loss: 0.0019 - val_mae: 0.0336 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0031 - mae: 0.0412 - val_loss: 0.0021 - val_mae: 0.0348 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 0.0033 - mae: 0.0420 - val_loss: 0.0020 - val_mae: 0.0340 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0028 - mae: 0.0391 - val_loss: 0.0020 - val_mae: 0.0338 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - loss: 0.0043 - mae: 0.0436 - val_loss: 0.0021 - val_mae: 0.0355 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 0.0020 - val_mae: 0.0346 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.0038 - mae: 0.0414 - val_loss: 0.0021 - val_mae: 0.0349 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0033 - mae: 0.0410 - val_loss: 0.0021 - val_mae: 0.0347 - learning_rate: 4.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 142ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0021 - val_mae: 0.0350 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001573. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 19 次實驗結果 (最後一項 Date_numeric: 20240321):\n",
            "LSTM模型預測結果: -0.046835042303428054%\n",
            "CNN+LSTM模型預測結果: 3.88188898563385%\n",
            "隨機森林模型預測結果: 1.6371296829628603%\n",
            "SVR模型預測結果: -1.7567489464146682%\n",
            "XGBoost模型預測結果: -5.270349979400635%\n",
            "Transformer模型預測結果: -0.7189210504293442%\n",
            "ARIMA+GARCH模型預測結果: [-1.18938879]%\n",
            "\n",
            "第 20 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 223ms/step - loss: 0.0735 - mae: 0.2114 - val_loss: 0.0071 - val_mae: 0.0671 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0262 - mae: 0.1260 - val_loss: 0.0017 - val_mae: 0.0304 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.0110 - mae: 0.0826 - val_loss: 0.0012 - val_mae: 0.0282 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 191ms/step - loss: 0.0049 - mae: 0.0543 - val_loss: 0.0012 - val_mae: 0.0266 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - loss: 0.0031 - mae: 0.0418 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 0.0024 - mae: 0.0366 - val_loss: 0.0011 - val_mae: 0.0270 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 188ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0011 - val_mae: 0.0266 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 219ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 199ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 229ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0259 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 155ms/step - loss: 0.2060 - mae: 0.3594 - val_loss: 0.0156 - val_mae: 0.1127 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0622 - mae: 0.1946 - val_loss: 0.0283 - val_mae: 0.1611 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 145ms/step - loss: 0.0115 - mae: 0.0832 - val_loss: 0.0083 - val_mae: 0.0806 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0071 - mae: 0.0640 - val_loss: 0.0131 - val_mae: 0.1057 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - loss: 0.0058 - mae: 0.0547 - val_loss: 0.0044 - val_mae: 0.0557 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0049 - mae: 0.0534 - val_loss: 0.0031 - val_mae: 0.0452 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0045 - mae: 0.0501 - val_loss: 0.0021 - val_mae: 0.0365 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - loss: 0.0039 - mae: 0.0449 - val_loss: 0.0023 - val_mae: 0.0374 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 147ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0020 - val_mae: 0.0346 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0036 - mae: 0.0439 - val_loss: 0.0023 - val_mae: 0.0380 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 0.0046 - mae: 0.0454 - val_loss: 0.0024 - val_mae: 0.0388 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - loss: 0.0033 - mae: 0.0429 - val_loss: 0.0025 - val_mae: 0.0399 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0037 - mae: 0.0412 - val_loss: 0.0023 - val_mae: 0.0376 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0021 - val_mae: 0.0357 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 0.0035 - mae: 0.0427 - val_loss: 0.0023 - val_mae: 0.0375 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 0.0037 - mae: 0.0420 - val_loss: 0.0024 - val_mae: 0.0386 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0029 - mae: 0.0390 - val_loss: 0.0026 - val_mae: 0.0405 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - loss: 0.0044 - mae: 0.0443 - val_loss: 0.0025 - val_mae: 0.0393 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0032 - mae: 0.0395 - val_loss: 0.0024 - val_mae: 0.0385 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001568. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 20 次實驗結果 (最後一項 Date_numeric: 20240422):\n",
            "LSTM模型預測結果: -0.19645595457404852%\n",
            "CNN+LSTM模型預測結果: 4.057995080947876%\n",
            "隨機森林模型預測結果: -2.7718142874288794%\n",
            "SVR模型預測結果: 0.4442471162883109%\n",
            "XGBoost模型預測結果: -1.288776658475399%\n",
            "Transformer模型預測結果: 2.569841593503952%\n",
            "ARIMA+GARCH模型預測結果: [-1.80514326]%\n",
            "\n",
            "第 21 次實驗：\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 235ms/step - loss: 0.1150 - mae: 0.2537 - val_loss: 0.0193 - val_mae: 0.1235 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0381 - mae: 0.1544 - val_loss: 0.0034 - val_mae: 0.0476 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - loss: 0.0170 - mae: 0.1002 - val_loss: 0.0012 - val_mae: 0.0263 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0077 - mae: 0.0679 - val_loss: 0.0010 - val_mae: 0.0257 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - loss: 0.0046 - mae: 0.0484 - val_loss: 8.7200e-04 - val_mae: 0.0222 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 221ms/step - loss: 0.0036 - mae: 0.0425 - val_loss: 8.5296e-04 - val_mae: 0.0221 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - loss: 0.0026 - mae: 0.0368 - val_loss: 8.2628e-04 - val_mae: 0.0212 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - loss: 0.0027 - mae: 0.0347 - val_loss: 8.1629e-04 - val_mae: 0.0213 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 8.2562e-04 - val_mae: 0.0211 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 8.1272e-04 - val_mae: 0.0212 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 199ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 8.1672e-04 - val_mae: 0.0215 - learning_rate: 2.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 8.1776e-04 - val_mae: 0.0215 - learning_rate: 2.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 8.1683e-04 - val_mae: 0.0215 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 8.1955e-04 - val_mae: 0.0216 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 224ms/step - loss: 0.0020 - mae: 0.0286 - val_loss: 8.1603e-04 - val_mae: 0.0214 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 195ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 8.1761e-04 - val_mae: 0.0215 - learning_rate: 4.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - loss: 0.0036 - mae: 0.0297 - val_loss: 8.1825e-04 - val_mae: 0.0216 - learning_rate: 4.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.1861e-04 - val_mae: 0.0216 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 8.1976e-04 - val_mae: 0.0216 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 253ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 8.1879e-04 - val_mae: 0.0216 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 169ms/step - loss: 0.1816 - mae: 0.3343 - val_loss: 0.0510 - val_mae: 0.2220 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.0357 - mae: 0.1487 - val_loss: 0.0022 - val_mae: 0.0348 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - loss: 0.0078 - mae: 0.0685 - val_loss: 0.0249 - val_mae: 0.1521 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0058 - mae: 0.0595 - val_loss: 0.0144 - val_mae: 0.1136 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 146ms/step - loss: 0.0049 - mae: 0.0532 - val_loss: 0.0068 - val_mae: 0.0752 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - loss: 0.0044 - mae: 0.0490 - val_loss: 0.0028 - val_mae: 0.0459 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 124ms/step - loss: 0.0041 - mae: 0.0463 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0039 - mae: 0.0465 - val_loss: 0.0015 - val_mae: 0.0294 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 162ms/step - loss: 0.0040 - mae: 0.0469 - val_loss: 0.0016 - val_mae: 0.0298 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - loss: 0.0037 - mae: 0.0441 - val_loss: 0.0014 - val_mae: 0.0282 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0014 - val_mae: 0.0282 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 157ms/step - loss: 0.0041 - mae: 0.0446 - val_loss: 0.0014 - val_mae: 0.0281 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 124ms/step - loss: 0.0030 - mae: 0.0409 - val_loss: 0.0016 - val_mae: 0.0293 - learning_rate: 2.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 0.0031 - mae: 0.0410 - val_loss: 0.0015 - val_mae: 0.0286 - learning_rate: 2.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 126ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0015 - val_mae: 0.0288 - learning_rate: 2.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 158ms/step - loss: 0.0029 - mae: 0.0406 - val_loss: 0.0016 - val_mae: 0.0294 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0017 - val_mae: 0.0315 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0016 - val_mae: 0.0295 - learning_rate: 4.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 171ms/step - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0016 - val_mae: 0.0301 - learning_rate: 4.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 155ms/step - loss: 0.0033 - mae: 0.0419 - val_loss: 0.0016 - val_mae: 0.0301 - learning_rate: 4.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 124ms/step - loss: 0.0032 - mae: 0.0412 - val_loss: 0.0016 - val_mae: 0.0298 - learning_rate: 4.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 0.0034 - mae: 0.0404 - val_loss: 0.0016 - val_mae: 0.0299 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arch/univariate/base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
            "estimating the model parameters. The scale of y is 0.001576. Parameter\n",
            "estimation work better when this value is between 1 and 1000. The recommended\n",
            "rescaling is 10 * y.\n",
            "\n",
            "This warning can be disabled by either rescaling y before initializing the\n",
            "model or by setting rescale=False.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n",
            "第 21 次實驗結果 (最後一項 Date_numeric: 20240131):\n",
            "LSTM模型預測結果: 0.21569801028817892%\n",
            "CNN+LSTM模型預測結果: 3.051261007785797%\n",
            "隨機森林模型預測結果: -13.00408428441333%\n",
            "SVR模型預測結果: -3.4170393113631596%\n",
            "XGBoost模型預測結果: -3.20315845310688%\n",
            "Transformer模型預測結果: -0.3451840952038765%\n",
            "ARIMA+GARCH模型預測結果: [-0.11025385]%\n",
            "\n",
            "第 22 次實驗：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQf3cjloMkHM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}